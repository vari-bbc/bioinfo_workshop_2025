Assuming unrestricted shared filesystem usage.
host: submit003
Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 2
Rules claiming more threads will be scaled down.
Job stats:
job              count
-------------  -------
all                  1
count_letters        1
total                2

Select jobs to execute...
Execute 1 jobs...
[Mon Oct 20 11:47:33 2025]
localrule count_letters:
    output: results/count_letters/foobar.txt
    jobid: 1
    reason: Missing output files: results/count_letters/foobar.txt; Code has changed since last execution
    wildcards: word=foobar
    resources: tmpdir=/var/tmp
[Mon Oct 20 11:47:33 2025]
Finished jobid: 1 (Rule: count_letters)
1 of 2 steps (50%) done
Select jobs to execute...
Execute 1 jobs...
[Mon Oct 20 11:47:33 2025]
localrule all:
    input: results/count_letters/foobar.txt
    jobid: 0
    reason: Input files updated by another job: results/count_letters/foobar.txt
    resources: tmpdir=/var/tmp
[Mon Oct 20 11:47:33 2025]
Finished jobid: 0 (Rule: all)
2 of 2 steps (100%) done
Complete log(s): /varidata/research/projects/bbc/research/bioinfo_workshop_2025/workshop_2/ex01/.snakemake/log/2025-10-20T114733.400348.snakemake.log
